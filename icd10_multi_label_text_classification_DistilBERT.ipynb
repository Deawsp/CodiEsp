{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "icd10-multi-label-text-classification-DistilBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6YXV2dFfcwI-",
        "ILcPscF4ddFh",
        "_mSAxlItpo0r"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deawsp/CodiEsp/blob/main/icd10_multi_label_text_classification_DistilBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v97uCeMHSkjw"
      },
      "source": [
        "#Importing python libraries and preparing the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Jc7fZizQ6jQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "853749ab-9c83-4e19-9fa9-17e20833501d"
      },
      "source": [
        "# Installing the transformer library\n",
        "!pip install -q transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 18.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 54.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2MB 52.4MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1d0Z1y-R3uw"
      },
      "source": [
        "# Importing stock ml libraries\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn import metrics\n",
        "import transformers\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMYoLo2rSUI3"
      },
      "source": [
        "# setting up the device for GPU usage\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhjaR8sgShXV"
      },
      "source": [
        "def hamming_score(y_true, y_pred, normalize=True, sample_weight=None):\n",
        "    acc_list = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        set_true = set( np.where(y_true[i])[0] )\n",
        "        set_pred = set( np.where(y_pred[i])[0] )\n",
        "        tmp_a = None\n",
        "        if len(set_true) == 0 and len(set_pred) == 0:\n",
        "            tmp_a = 1\n",
        "        else:\n",
        "            tmp_a = len(set_true.intersection(set_pred))/\\\n",
        "                    float( len(set_true.union(set_pred)) )\n",
        "        acc_list.append(tmp_a)\n",
        "    return np.mean(acc_list)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx68_OiHFGj4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4F--wGSSxLd"
      },
      "source": [
        "# Importing and Pre-Processing the domain data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg-lCPyHTyIF",
        "outputId": "193c8b20-d107-49a8-cd70-e97fa44fe95a"
      },
      "source": [
        "# # # mount colab to google drive\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djLO4cOnS3CL"
      },
      "source": [
        "import zipfile\n",
        "my_zipfolder = '/content/gdrive/MyDrive/icd10_multi_label_classification/train.csv.zip'\n",
        "with zipfile.ZipFile(my_zipfolder, 'r') as zip_ref:\n",
        "  zip_ref.extractall('working_directory')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n7Fo572lTgoU",
        "outputId": "198a54e4-d4a6-4297-aaaa-1f673685ac79"
      },
      "source": [
        "# my_ziptrain = '/content/working_directory/train.csv.zip'\n",
        "# with zipfile.ZipFile(my_ziptrain, 'r') as zip_reftrain:\n",
        "#   zip_reftrain.extractall('data')\n",
        "\n",
        "\n",
        "import os   \n",
        "import shutil \n",
        "os.mkdir(\"data\")\n",
        "shutil.move(\"/content/working_directory/train.csv\", \"/content/data\") \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/data/train.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "rNo2AVZZUyLc",
        "outputId": "300c5a52-0890-44cd-fb91-7954d50f19c0"
      },
      "source": [
        "df = pd.read_csv('/content/data/train.csv')\n",
        "df['list'] = df[df.columns[2:]].values.tolist() #Create new column call list \n",
        "new_df = df[['text', 'list']].copy()\n",
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['A 62-year-old woman with a history of arteri...</td>\n",
              "      <td>[1, 0, 1, 1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['A 4-year-old patient presented with tirednes...</td>\n",
              "      <td>[1, 0, 1, 0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['A 72-year-old male diagnosed with primary op...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['A 49-year-old male smoker of 12 cigarettes a...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['A 39-year-old male patient presented to the ...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                   list\n",
              "0  ['A 62-year-old woman with a history of arteri...  [1, 0, 1, 1, 0, 0, 0]\n",
              "1  ['A 4-year-old patient presented with tirednes...  [1, 0, 1, 0, 0, 1, 0]\n",
              "2  ['A 72-year-old male diagnosed with primary op...  [1, 0, 0, 0, 0, 0, 0]\n",
              "3  ['A 49-year-old male smoker of 12 cigarettes a...  [1, 0, 0, 0, 0, 0, 0]\n",
              "4  ['A 39-year-old male patient presented to the ...  [1, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwcKyX1cYPap"
      },
      "source": [
        "#Preparing the dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktzsdavUVBSQ"
      },
      "source": [
        "# Sections of config\n",
        "# Defining some key variables that will be used later on in the triaining\n",
        "MAX_LEN =  512 # change to 512 instead of 200\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 4\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 1e-05\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGarGwKQb3YL"
      },
      "source": [
        "class MultiLabelDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.targets = self.data.list\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFFy4m5qcdD-",
        "outputId": "0c8a5a16-b6ab-427a-a0b0-71dedae5c16b"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset=new_df.sample(frac=train_size,random_state=200)\n",
        "test_dataset=new_df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FULL Dataset: (339, 2)\n",
            "TRAIN Dataset: (271, 2)\n",
            "TEST Dataset: (68, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgTdGb6RcfUD"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O8SXx99chx6"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YXV2dFfcwI-"
      },
      "source": [
        "#Creating the Neural Network for Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbMR5CK-c1-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53418d3b-a904-41c1-d8d3-f915e83984d8"
      },
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
        "\n",
        "class DistilBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistilBERTClass, self).__init__()\n",
        "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.classifier = torch.nn.Linear(768, 7)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.Tanh()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output\n",
        "\n",
        "model = DistilBERTClass()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBERTClass(\n",
              "  (l1): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hT_7-tHc9iL"
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFqkfRr7dXiS"
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfhSrLybda9W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILcPscF4ddFh"
      },
      "source": [
        "#Fine Tuning the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcOOQMEHdgN0"
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _,data in enumerate(training_loader, 0):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.float)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids, )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _%5000==0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "         \n",
        "            # logger.info(f'Epoch:{epoch}, Loss: {loss.item()}'\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z74bnkqOd0UC"
      },
      "source": [
        "def validation():\n",
        "    model.eval()\n",
        "    fin_targets=[]\n",
        "    fin_outputs=[]\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(testing_loader, 0):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u6U4jYBuTv6"
      },
      "source": [
        "import logging\n",
        "import warnings                        # To ignore any warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# a function  to create and save logs in the log files\n",
        "def log(path, file):\n",
        "\n",
        "    \"\"\"[Create a log file to record the experiment's logs]\n",
        "    \n",
        "    Arguments:\n",
        "        path {string} -- path to the directory\n",
        "        file {string} -- file name\n",
        "    \n",
        "    Returns:\n",
        "        [obj] -- [logger that record logs]\n",
        "    \"\"\"\n",
        "\n",
        "    # check if the file exist\n",
        "    log_file = os.path.join(path, file)\n",
        "\n",
        "    if not os.path.isfile(log_file):\n",
        "        open(log_file, \"w+\").close()\n",
        "\n",
        "    console_logging_format = \"%(message)s\"\n",
        "    file_logging_format = \"%(message)s\"\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    # in case we want loglevel and time \n",
        "    # console_logging_format = \"%(levelname)s %(message)s\"\n",
        "    # file_logging_format = \"%(levelname)s: %(asctime)s: %(message)s\"\n",
        "\n",
        "    # configure logger\n",
        "    logging.basicConfig(level=logging.INFO, format=console_logging_format)\n",
        "    logger = logging.getLogger()\n",
        "    \n",
        "    # create a file handler for output file\n",
        "    handler = logging.FileHandler(log_file)\n",
        "\n",
        "    # set the logging level for log file\n",
        "    handler.setLevel(logging.INFO)\n",
        "    \n",
        "    # create a logging format\n",
        "    formatter = logging.Formatter(file_logging_format)\n",
        "    handler.setFormatter(formatter)\n",
        "    \n",
        "\n",
        "    # add the handlers to the logger\n",
        "    logger.addHandler(handler)\n",
        "\n",
        "    return logger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUGGVFGL3T2m"
      },
      "source": [
        "# set a logger file\n",
        "# os.mkdir(\"logs\")\n",
        "\n",
        "path = \"/content/logs\"\n",
        "logger = log(path, file=\"train.logs\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5NHyjOCdqtj",
        "outputId": "5d7d0b38-2ce9-4d7f-f03c-35e7bb066262"
      },
      "source": [
        "# logger.info(\"Start Training\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)\n",
        "    outputs, targets = validation()\n",
        "    outputs = np.array(outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\n",
        "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "\n",
        "    # logger.info(f\"{accuracy}, {f1_score_micro}, {f1_score_macro}\")\n",
        "\n",
        "    # logger.info(f\"{f1_score_micro},\")\n",
        "    # logger.info(f\"{f1_score_macro},\")\n",
        "    # logger.info(f\"Accuracy Score = {accuracy} ,\")\n",
        "    # logger.info(f\"F1 Score (Micro) = {f1_score_micro} ,\")\n",
        "    # logger.info(f\"F1 Score (Macro) = {f1_score_macro} ,\")\n",
        "\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss:  0.7058376669883728\n",
            "Accuracy Score = 0.0\n",
            "F1 Score (Micro) = 0.0\n",
            "F1 Score (Macro) = 0.0\n",
            "\n",
            "Epoch: 1, Loss:  0.5376745462417603\n",
            "Accuracy Score = 0.0\n",
            "F1 Score (Micro) = 0.0\n",
            "F1 Score (Macro) = 0.0\n",
            "\n",
            "Epoch: 2, Loss:  0.5997713804244995\n",
            "Accuracy Score = 0.0\n",
            "F1 Score (Micro) = 0.0\n",
            "F1 Score (Macro) = 0.0\n",
            "\n",
            "Epoch: 3, Loss:  0.5152737498283386\n",
            "Accuracy Score = 0.0\n",
            "F1 Score (Micro) = 0.0\n",
            "F1 Score (Macro) = 0.0\n",
            "\n",
            "Epoch: 4, Loss:  0.5746962428092957\n",
            "Accuracy Score = 0.014705882352941176\n",
            "F1 Score (Micro) = 0.015037593984962407\n",
            "F1 Score (Macro) = 0.009523809523809523\n",
            "\n",
            "Epoch: 5, Loss:  0.495268851518631\n",
            "Accuracy Score = 0.11764705882352941\n",
            "F1 Score (Micro) = 0.40963855421686746\n",
            "F1 Score (Macro) = 0.261352843024002\n",
            "\n",
            "Epoch: 6, Loss:  0.45978689193725586\n",
            "Accuracy Score = 0.16176470588235295\n",
            "F1 Score (Micro) = 0.4606741573033708\n",
            "F1 Score (Macro) = 0.3263853263853264\n",
            "\n",
            "Epoch: 7, Loss:  0.3597797155380249\n",
            "Accuracy Score = 0.14705882352941177\n",
            "F1 Score (Micro) = 0.4457142857142857\n",
            "F1 Score (Macro) = 0.31528299657331915\n",
            "\n",
            "Epoch: 8, Loss:  0.29893597960472107\n",
            "Accuracy Score = 0.19117647058823528\n",
            "F1 Score (Micro) = 0.48\n",
            "F1 Score (Macro) = 0.33284325737155923\n",
            "\n",
            "Epoch: 9, Loss:  0.3078913688659668\n",
            "Accuracy Score = 0.20588235294117646\n",
            "F1 Score (Micro) = 0.45901639344262296\n",
            "F1 Score (Macro) = 0.345802209772798\n",
            "\n",
            "Epoch: 10, Loss:  0.3918057382106781\n",
            "Accuracy Score = 0.17647058823529413\n",
            "F1 Score (Micro) = 0.45054945054945056\n",
            "F1 Score (Macro) = 0.343984593837535\n",
            "\n",
            "Epoch: 11, Loss:  0.3145195543766022\n",
            "Accuracy Score = 0.22058823529411764\n",
            "F1 Score (Micro) = 0.5170731707317072\n",
            "F1 Score (Macro) = 0.43759296259296254\n",
            "\n",
            "Epoch: 12, Loss:  0.20535221695899963\n",
            "Accuracy Score = 0.19117647058823528\n",
            "F1 Score (Micro) = 0.5023696682464456\n",
            "F1 Score (Macro) = 0.4268233435880494\n",
            "\n",
            "Epoch: 13, Loss:  0.20587371289730072\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.523076923076923\n",
            "F1 Score (Macro) = 0.43246606334841636\n",
            "\n",
            "Epoch: 14, Loss:  0.21263886988162994\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5526315789473685\n",
            "F1 Score (Macro) = 0.474204325086678\n",
            "\n",
            "Epoch: 15, Loss:  0.1787290722131729\n",
            "Accuracy Score = 0.22058823529411764\n",
            "F1 Score (Micro) = 0.5412844036697247\n",
            "F1 Score (Macro) = 0.46448717506877607\n",
            "\n",
            "Epoch: 16, Loss:  0.15549728274345398\n",
            "Accuracy Score = 0.22058823529411764\n",
            "F1 Score (Micro) = 0.5420560747663551\n",
            "F1 Score (Macro) = 0.47292017039916195\n",
            "\n",
            "Epoch: 17, Loss:  0.14334331452846527\n",
            "Accuracy Score = 0.19117647058823528\n",
            "F1 Score (Micro) = 0.5570776255707763\n",
            "F1 Score (Macro) = 0.4940814077026702\n",
            "\n",
            "Epoch: 18, Loss:  0.12290073186159134\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5463414634146341\n",
            "F1 Score (Macro) = 0.4526784423843247\n",
            "\n",
            "Epoch: 19, Loss:  0.1212400496006012\n",
            "Accuracy Score = 0.20588235294117646\n",
            "F1 Score (Micro) = 0.5686274509803921\n",
            "F1 Score (Macro) = 0.4920659524240087\n",
            "\n",
            "Epoch: 20, Loss:  0.085401251912117\n",
            "Accuracy Score = 0.22058823529411764\n",
            "F1 Score (Micro) = 0.5700934579439252\n",
            "F1 Score (Macro) = 0.5116114821997175\n",
            "\n",
            "Epoch: 21, Loss:  0.10785767436027527\n",
            "Accuracy Score = 0.20588235294117646\n",
            "F1 Score (Micro) = 0.5607476635514018\n",
            "F1 Score (Macro) = 0.4985939756837589\n",
            "\n",
            "Epoch: 22, Loss:  0.08078053593635559\n",
            "Accuracy Score = 0.19117647058823528\n",
            "F1 Score (Micro) = 0.5353535353535352\n",
            "F1 Score (Macro) = 0.45833404068698186\n",
            "\n",
            "Epoch: 23, Loss:  0.07391270995140076\n",
            "Accuracy Score = 0.25\n",
            "F1 Score (Micro) = 0.5925925925925926\n",
            "F1 Score (Macro) = 0.5369908647219571\n",
            "\n",
            "Epoch: 24, Loss:  0.08598234504461288\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5560975609756097\n",
            "F1 Score (Macro) = 0.48586960161912723\n",
            "\n",
            "Epoch: 25, Loss:  0.07028566300868988\n",
            "Accuracy Score = 0.27941176470588236\n",
            "F1 Score (Micro) = 0.5786802030456852\n",
            "F1 Score (Macro) = 0.4935820998839075\n",
            "\n",
            "Epoch: 26, Loss:  0.07163362950086594\n",
            "Accuracy Score = 0.22058823529411764\n",
            "F1 Score (Micro) = 0.548076923076923\n",
            "F1 Score (Macro) = 0.4677152030402804\n",
            "\n",
            "Epoch: 27, Loss:  0.06701298803091049\n",
            "Accuracy Score = 0.22058823529411764\n",
            "F1 Score (Micro) = 0.5631067961165048\n",
            "F1 Score (Macro) = 0.5014945609372854\n",
            "\n",
            "Epoch: 28, Loss:  0.06148529052734375\n",
            "Accuracy Score = 0.20588235294117646\n",
            "F1 Score (Micro) = 0.5463917525773195\n",
            "F1 Score (Macro) = 0.4597227780000889\n",
            "\n",
            "Epoch: 29, Loss:  0.0647774338722229\n",
            "Accuracy Score = 0.27941176470588236\n",
            "F1 Score (Micro) = 0.5757575757575758\n",
            "F1 Score (Macro) = 0.48446509917098146\n",
            "\n",
            "Epoch: 30, Loss:  0.05517193675041199\n",
            "Accuracy Score = 0.2647058823529412\n",
            "F1 Score (Micro) = 0.5870646766169154\n",
            "F1 Score (Macro) = 0.5089112412641824\n",
            "\n",
            "Epoch: 31, Loss:  0.056411199271678925\n",
            "Accuracy Score = 0.22058823529411764\n",
            "F1 Score (Micro) = 0.5658536585365853\n",
            "F1 Score (Macro) = 0.49123053053595517\n",
            "\n",
            "Epoch: 32, Loss:  0.048551734536886215\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5599999999999999\n",
            "F1 Score (Macro) = 0.48778400248988485\n",
            "\n",
            "Epoch: 33, Loss:  0.04671042785048485\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5714285714285714\n",
            "F1 Score (Macro) = 0.4917481288796405\n",
            "\n",
            "Epoch: 34, Loss:  0.04391740635037422\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5841584158415842\n",
            "F1 Score (Macro) = 0.5143077107023976\n",
            "\n",
            "Epoch: 35, Loss:  0.045359544456005096\n",
            "Accuracy Score = 0.22058823529411764\n",
            "F1 Score (Micro) = 0.5686274509803921\n",
            "F1 Score (Macro) = 0.498668220610945\n",
            "\n",
            "Epoch: 36, Loss:  0.03724553808569908\n",
            "Accuracy Score = 0.22058823529411764\n",
            "F1 Score (Micro) = 0.5700483091787439\n",
            "F1 Score (Macro) = 0.5069799089226333\n",
            "\n",
            "Epoch: 37, Loss:  0.03713679313659668\n",
            "Accuracy Score = 0.25\n",
            "F1 Score (Micro) = 0.5812807881773399\n",
            "F1 Score (Macro) = 0.5112280292233853\n",
            "\n",
            "Epoch: 38, Loss:  0.03702564537525177\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5645933014354068\n",
            "F1 Score (Macro) = 0.4888826343934703\n",
            "\n",
            "Epoch: 39, Loss:  0.030167683959007263\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5971563981042655\n",
            "F1 Score (Macro) = 0.5404383975812547\n",
            "\n",
            "Epoch: 40, Loss:  0.02791941910982132\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5779816513761468\n",
            "F1 Score (Macro) = 0.5182887874876095\n",
            "\n",
            "Epoch: 41, Loss:  0.03967219218611717\n",
            "Accuracy Score = 0.22058823529411764\n",
            "F1 Score (Micro) = 0.5588235294117647\n",
            "F1 Score (Macro) = 0.48540370485618833\n",
            "\n",
            "Epoch: 42, Loss:  0.030836379155516624\n",
            "Accuracy Score = 0.20588235294117646\n",
            "F1 Score (Micro) = 0.580952380952381\n",
            "F1 Score (Macro) = 0.5145061027413969\n",
            "\n",
            "Epoch: 43, Loss:  0.032835979014635086\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5876777251184835\n",
            "F1 Score (Macro) = 0.5277151796391071\n",
            "\n",
            "Epoch: 44, Loss:  0.026448162272572517\n",
            "Accuracy Score = 0.25\n",
            "F1 Score (Micro) = 0.5990338164251208\n",
            "F1 Score (Macro) = 0.5363019476796567\n",
            "\n",
            "Epoch: 45, Loss:  0.032664235681295395\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.580952380952381\n",
            "F1 Score (Macro) = 0.5173370517797762\n",
            "\n",
            "Epoch: 46, Loss:  0.02382507175207138\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5821596244131455\n",
            "F1 Score (Macro) = 0.523420532487317\n",
            "\n",
            "Epoch: 47, Loss:  0.025711629539728165\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.575609756097561\n",
            "F1 Score (Macro) = 0.5092439022392583\n",
            "\n",
            "Epoch: 48, Loss:  0.019977618008852005\n",
            "Accuracy Score = 0.23529411764705882\n",
            "F1 Score (Micro) = 0.5865384615384616\n",
            "F1 Score (Macro) = 0.5278264130755891\n",
            "\n",
            "Epoch: 49, Loss:  0.021980365738272667\n",
            "Accuracy Score = 0.20588235294117646\n",
            "F1 Score (Micro) = 0.5781990521327014\n",
            "F1 Score (Macro) = 0.516493596988953\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "Gt8z8qesuZ1R",
        "outputId": "737a1a36-af14-4260-83c1-64fbb15bd960"
      },
      "source": [
        "import pandas as pd\n",
        "import pylab as plt\n",
        "\n",
        "# Create dataframe\n",
        "file_name = \"/content/logs/train.logs\"\n",
        "dflog = pd.read_csv(file_name)\n",
        "# dflog.plot()\n",
        "# plt.show()\n",
        "dflog.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.3235294117647059</th>\n",
              "      <th>0.6602870813397129</th>\n",
              "      <th>0.6159376532275693</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.323529</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.622765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.338235</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.627880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.382353</td>\n",
              "      <td>0.681416</td>\n",
              "      <td>0.646638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.338235</td>\n",
              "      <td>0.669725</td>\n",
              "      <td>0.634705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.308824</td>\n",
              "      <td>0.657277</td>\n",
              "      <td>0.619133</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0.3235294117647059   0.6602870813397129   0.6159376532275693 \n",
              "44            0.323529             0.666667              0.622765\n",
              "45            0.338235             0.666667              0.627880\n",
              "46            0.382353             0.681416              0.646638\n",
              "47            0.338235             0.669725              0.634705\n",
              "48            0.308824             0.657277              0.619133"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mSAxlItpo0r"
      },
      "source": [
        "#Validating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjbGRVGwvo0w"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    outputs, targets = validation(epoch)\n",
        "    outputs = np.array(outputs) >= 0.5\n",
        "    accuracy = metrics.accuracy_score(targets, outputs)\n",
        "    f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "    f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "    print(f\"F1 Score (Macro) = {f1_score_macro}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02AgiC3C3TM1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}